import streamlit as st
import pandas as pd
import joblib
import json
from dotenv import load_dotenv
import os
import requests # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ requests ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API

# ‡πÇ‡∏´‡∏•‡∏î .env (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
load_dotenv()

# --- Page Config ---
st.set_page_config(page_title="NPL Prediction App", page_icon="üí∏", layout="wide")

# --- ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ options ---
@st.cache_resource
def load_resources():
    """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Machine Learning ‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå options."""
    try:
        model = joblib.load('pipeline.joblib')
        with open('options.json', 'r', encoding='utf8') as f:
            options = json.load(f)
        return model, options
    except FileNotFoundError:
        st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• 'pipeline.joblib' ‡∏´‡∏£‡∏∑‡∏≠ 'options.json'. ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡πà‡∏≠‡∏ô.")
        st.stop()
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£: {e}")
        st.stop()

model, options = load_resources()

# --- UI ‡∏´‡∏•‡∏±‡∏Å ---
st.title("üí∏ ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏î‡πâ‡∏≤‡∏ô‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠")

col_app, col_info = st.columns([2,1])

with col_app:
    st.header("‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á NPL")
    st.write("‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏Ç‡∏≠‡∏á‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏´‡∏°‡πà")

    with st.form("input_form"):
        st.subheader("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å")
        c1, c2 = st.columns(2)
        with c1:
            occupation = st.selectbox("‡∏≠‡∏≤‡∏ä‡∏µ‡∏û (Occupation)", options=options['‡∏≠‡∏≤‡∏ä‡∏µ‡∏û'])
            purpose = st.selectbox("‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå (Purpose)", options=options['‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå'])
            status = st.selectbox("‡∏™‡∏ñ‡∏≤‡∏ô‡∏†‡∏≤‡∏û (Marital Status)", options=options['‡∏™‡∏ñ‡∏≤‡∏ô‡∏†‡∏≤‡∏û'])
            gender = st.selectbox("‡πÄ‡∏û‡∏® (Gender)", options=options['‡πÄ‡∏û‡∏®'])
        with c2:
            income = st.number_input("‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ (‡∏ï‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)", min_value=0, value=15000, step=500)
            loan_amount = st.number_input("‡∏ß‡∏á‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≠", min_value=0, value=50000, step=1000)
            monthly_payment = st.number_input("‡∏ä‡∏≥‡∏£‡∏∞‡∏ï‡πà‡∏≠‡∏á‡∏ß‡∏î (‡∏ö‡∏≤‡∏ó‡∏ï‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)", min_value=0, value=2000, step=500)
        submitted = st.form_submit_button("‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")

    if submitted:
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏ä‡∏≥‡∏£‡∏∞‡∏ï‡πà‡∏≠‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ (DTI)
        dti_calculated = (monthly_payment / income) * 100 if income > 0 else 0
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡πâ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•
        input_data = pd.DataFrame({
            '‡∏≠‡∏≤‡∏ä‡∏µ‡∏û': [occupation],
            '‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå': [purpose],
            '‡∏™‡∏ñ‡∏≤‡∏ô‡∏†‡∏≤‡∏û': [status],
            '‡πÄ‡∏û‡∏®': [gender],
            '‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ': [income],
            '‡∏ß‡∏á‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≠': [loan_amount],
            '‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏ä‡∏≥‡∏£‡∏∞‡∏ï‡πà‡∏≠‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ': [dti_calculated]
        })
        
        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á NPL
        predict_proba = model.predict_proba(input_data)[0]
        npl_probability = predict_proba[1] # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô NPL (‡∏Ñ‡∏•‡∏≤‡∏™ 1)

        st.subheader("üéØ ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô")
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á
        if npl_probability < 0.25:
            st.success(f"**‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ï‡πà‡∏≥** (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô NPL: {npl_probability:.2%})", icon="‚úÖ")
        elif npl_probability < 0.50:
            st.info(f"**‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á** (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô NPL: {npl_probability:.2%})", icon="ü§î")
        elif npl_probability < 0.75:
            st.warning(f"**‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á** (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô NPL: {npl_probability:.2%})", icon="‚ö†Ô∏è")
        else:
            st.error(f"**‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å** (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô NPL: {npl_probability:.2%})", icon="üö®")
        
        st.progress(npl_probability) # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ñ‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        st.caption("‡πÅ‡∏ñ‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏£‡∏≤‡∏¢‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ô‡∏µ‡πâ‡πÄ‡∏™‡∏µ‡∏¢ (NPL)")

# --- Chatbot ‡∏ù‡∏±‡πà‡∏á‡∏Ç‡∏ß‡∏≤ ---
with col_info:
    st.header("ü§ñ ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤")
    st.write("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å AI ‡∏£‡∏∞‡∏î‡∏±‡∏ö Gemini Flash") # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°

    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ä‡∏ó‡πÉ‡∏ô session_state
    if "messages" not in st.session_state:
        st.session_state.messages = [
            # System role ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≥‡∏´‡∏ô‡∏î Persona ‡∏Ç‡∏≠‡∏á AI ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏™‡πà‡∏á‡∏ï‡∏£‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á API payload
            {"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡∏™‡∏´‡∏Å‡∏£‡∏ì‡πå ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á NPL ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏∏‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢"},
            {"role": "assistant", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ú‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô NPL ‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?"}
        ]

    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ä‡∏ó‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ (‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á assistant ‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å)
    for msg in st.session_state.messages[1:]: 
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # ‡∏£‡∏±‡∏ö input ‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
    if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏≠‡∏ö..."):
                try:
                    # ‡∏î‡∏∂‡∏á Gemini API Key ‡∏à‡∏≤‡∏Å environment variables
                    gemini_api_key = os.getenv("GEMINI_API_KEY")
                    
                    if not gemini_api_key:
                        assistant_reply = "‡πÑ‡∏°‡πà‡∏û‡∏ö GEMINI_API_KEY ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .env ‡∏´‡∏£‡∏∑‡∏≠ Environment Variables. ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô."
                    else:
                        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á Gemini API
                        # ‡πÅ‡∏õ‡∏•‡∏á 'assistant' role ‡πÄ‡∏õ‡πá‡∏ô 'model' role ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Gemini
                        gemini_messages_for_api = []
                        for msg in st.session_state.messages:
                            if msg["role"] == "user":
                                gemini_messages_for_api.append({"role": "user", "parts": [{"text": msg["content"]}]})
                            elif msg["role"] == "assistant":
                                gemini_messages_for_api.append({"role": "model", "parts": [{"text": msg["content"]}]})
                            # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á 'system' role ‡πÑ‡∏õ‡πÉ‡∏ô payload ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á

                        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î URL ‡∏Ç‡∏≠‡∏á Gemini API (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö gemini-2.0-flash)
                        api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={gemini_api_key}"
                        
                        # ‡∏™‡∏£‡πâ‡∏≤‡∏á payload ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö request
                        payload = {
                            "contents": gemini_messages_for_api,
                            "generationConfig": {
                                "temperature": 0.5, # ‡∏õ‡∏£‡∏±‡∏ö temperature ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
                            }
                        }

                        # ‡∏™‡πà‡∏á POST request ‡πÑ‡∏õ‡∏¢‡∏±‡∏á Gemini API
                        response = requests.post(api_url, headers={'Content-Type': 'application/json'}, json=payload)
                        response.raise_for_status() # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î HTTP status (‡πÄ‡∏ä‡πà‡∏ô 4xx, 5xx)
                        result = response.json()

                        # ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å response ‡∏Ç‡∏≠‡∏á Gemini API
                        if result.get("candidates") and len(result["candidates"]) > 0 and \
                           result["candidates"][0].get("content") and \
                           len(result["candidates"][0]["content"].get("parts", [])) > 0:
                            assistant_reply = result["candidates"][0]["content"]["parts"][0]["text"]
                        else:
                            assistant_reply = "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å Gemini API ‡πÑ‡∏î‡πâ (‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ candidates)."
                
                except requests.exceptions.RequestException as req_err:
                    assistant_reply = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Gemini API: {req_err}. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö API Key ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì."
                except json.JSONDecodeError:
                    assistant_reply = "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡∏£‡∏´‡∏±‡∏™ JSON ‡∏à‡∏≤‡∏Å Gemini API (‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á)."
                except Exception as e:
                    assistant_reply = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î: {e}"

            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á AI ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏•‡∏á‡πÉ‡∏ô session_state
            st.markdown(assistant_reply)
            st.session_state.messages.append({"role": "assistant", "content": assistant_reply})





    #st.caption("‡πÅ‡∏ñ‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏£‡∏≤‡∏¢‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ô‡∏µ‡πâ‡πÄ‡∏™‡∏µ‡∏¢ (NPL)")#.\venv\Scripts\activate#streamlit run app.py
